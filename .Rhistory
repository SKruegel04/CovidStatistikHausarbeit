y2 <- y1^4
y3 <- (x - 50)^2 + 30 * e
data1 <- data.frame(x=x, y=y1)
data2 <- data.frame(x=x, y=y2)
data3 <- data.frame(x=x, y=y3)
pearson1 <- cor(data1$x, data1$y)
pearson1
pearson2 <- cor(data2$x, data2$y)
pearson2
pearson3 <- cor(data3$x, data3$y)
pearson3
pearson3 <- cor(data3$x, data3$y)
pearson3
kendall1 <- cor(data1$x, data1$y, method="kendall")
kendall1
pearson2 <- cor(data2$x, data2$y)
pearson2
kendall2 <- cor(data2$x, data2$y, method="kendall")
kendall2
#Data3
pearson3 <- cor(data3$x, data3$y)
pearson3
kendall3 <- cor(data3$x, data3$y, method="kendall")
kendall3
dataCor1
dataCor1 <- cor(data1$x, data1$y, method = c("pearson", "kendall", "spearman"))
y1 <- x + e
y2 <- y1^4
y3 <- (x - 50)^2 + 30 * e
data1 <- data.frame(x=x, y=y1)
data2 <- data.frame(x=x, y=y2)
data3 <- data.frame(x=x, y=y3)
#Data1
pearson1 <- cor(data1$x, data1$y)
pearson1
kendall1 <- cor(data1$x, data1$y, method="kendall")
kendall1
dataCor1 <- cor(data1$x, data1$y, method = c("pearson", "kendall", "spearman"))
dataCor1
#Data2
pearson2 <- cor(data2$x, data2$y)
pearson2
kendall2 <- cor(data2$x, data2$y, method="kendall")
kendall2
#Data3
pearson3 <- cor(data3$x, data3$y)
pearson3
kendall3 <- cor(data3$x, data3$y, method="kendall")
kendall3
dataCor1
dataCor1
spearman1
<- cor(data1$x, data1$y, method="spearman")
spearman1
spearman1 <- cor(data1$x, data1$y, method="spearman")
spearman
y1 <- x + e
y2 <- y1^4
y3 <- (x - 50)^2 + 30 * e
data1 <- data.frame(x=x, y=y1)
data2 <- data.frame(x=x, y=y2)
data3 <- data.frame(x=x, y=y3)
#Data1
pearson1 <- cor(data1$x, data1$y)
pearson1
kendall1 <- cor(data1$x, data1$y, method="kendall")
kendall1
spearman1 <- cor(data1$x, data1$y, method="spearman")
spearman1
#Data2
pearson2 <- cor(data2$x, data2$y)
pearson2
kendall2 <- cor(data2$x, data2$y, method="kendall")
kendall2
spearman2 <- cor(data1$x, data1$y, method="spearman")
spearman2
#Data3
pearson3 <- cor(data3$x, data3$y)
pearson3
kendall3 <- cor(data3$x, data3$y, method="kendall")
kendall3
spearman3 <- cor(data1$x, data1$y, method="spearman")
spearman3
spearman1
spearman3
spearman3 <- cor(data3$x, data3$y, method="spearman")
spearman3
pearson1
kendall1
spearman1
pearson2
kendall2
spearman2
plot(data1$x, data1$y)
plot(data2$x, data2$y)
plot(data3$x, data3$y)
pearson1
kendall1 <- cor(data1$x, data1$y, method="kendall")
kendall1
spearman1 <- cor(data1$x, data1$y, method="spearman")
spearman1
pearson1 <- cor(data1$x, data1$y)
pearson1
kendall1 <- cor(data1$x, data1$y, method="kendall")
kendall1
spearman1 <- cor(data1$x, data1$y, method="spearman")
spearman1
#Data2
pearson2 <- cor(data2$x, data2$y)
pearson2
kendall2 <- cor(data2$x, data2$y, method="kendall")
kendall2
spearman2 <- cor(data2$x, data2$y, method="spearman")
spearman2
#Data3
pearson3 <- cor(data3$x, data3$y)
pearson3
kendall3 <- cor(data3$x, data3$y, method="kendall")
kendall3
spearman3 <- cor(data3$x, data3$y, method="spearman")
spearman3
plot(data1$x, data1$y)
plot(data2$x, data2$y)
plot(data3$x, data3$y)
#Data1
pearson1 <- cor(data1$x, data1$y)
pearson1
kendall1 <- cor(data1$x, data1$y, method="kendall")
kendall1
spearman1 <- cor(data1$x, data1$y, method="spearman")
spearman1
#Data2
pearson2 <- cor(data2$x, data2$y)
pearson2
kendall2 <- cor(data2$x, data2$y, method="kendall")
kendall2
spearman2 <- cor(data2$x, data2$y, method="spearman")
spearman2
#Data3
pearson3 <- cor(data3$x, data3$y)
pearson3
kendall3 <- cor(data3$x, data3$y, method="kendall")
kendall3
spearman3 <- cor(data3$x, data3$y, method="spearman")
spearman3
library(base)
knitr::opts_chunk$set(echo = TRUE)
library(BSDA)
#a)
str(Readiq)
#a)
str(Readiq)
summary(Readiq)
dim(Readiq)
#Die beiden Merkmale sind "reading" und "IQ"
#b)
plot(Readiq$reading, Readiq$iq, main="Scatterplott IQ/Lesen",
xlab="Lesezeit", ylab="IQ", pch=19)
#c)
#Korrelationskoeffizient
cor(Readiq$reading, Readiq$iq) #Es besteht eine starke positive Korrelation zwischen beiden
# Merkmalen. Das bedeutet, dass Menschen mit einem höheren IQ mehr Zeit mit Lesen verbringen
# und umgekehrt, dass je mehr Zeit mit Lesen verbracht wird, der IQ höher ist.
#d)
mittelwertIq <- mean(Readiq$iq)
mittelwertReading <- mean(Readiq$reading)
mittelwertIq
standardabweichungIq <- sd(Readiq$iq)
standardabweichungReading <- sd(Readiq$reading)
korrelation <- cor(Readiq$reading, Readiq$iq)
kovariation <- cov(Readiq$reading, Readiq$iq)
kovariation
b <- (standardabweichungIq / standardabweichungReading) * korrelation
b
a <- (-(standardabweichungIq / standardabweichungReading) * korrelation * mittelwertReading + mittelwertIq)
a
#Regressionsgleichung
erwarteterIq <- (b * 60) + a
erwarteterIq #Bei 60 min lesen beträgt der IQ vorraussichtlich 124.
#e)
# Fit regression line
require(stats)
reg<-lm(Readiq$iq ~ Readiq$reading, data = Readiq)
# plot
plot(Readiq, main=eq)
abline(reg, col="blue")
b
a
```{r}
library(knitr)
mindestlohn_tabelle <- data.frame(row.names = c("Irland", "Frankreich", "Großbritannien",
"Belgien", "Niederlande", "USA", "Spanien"),
Mindestlohn = c(8.65, 4.44, 8.2, 8.08, 8.08, 4.3, 3.42),
Arbeitslosenquote = c(4.4, 9.0, 5.5, 8.2, 5.5, 4.6, 8.5))
kable(mindestlohn_tabelle)
plot(mindestlohn_tabelle$Mindestlohn, mindestlohn_tabelle$Arbeitslosenquote)
#Es gibt keinen linearen Zusammenhang.
mittelwertQuote <- mean(mindestlohn_tabelle$Arbeitslosenquote)
mittelwertLohn <- mean(mindestlohn_tabelle$Mindestlohn)
standardabweichungQuote <- sd(mindestlohn_tabelle$Arbeitslosenquote)
standardabweichungLohn <- sd(mindestlohn_tabelle$Mindestlohn)
korrelation <- cor(mindestlohn_tabelle$Mindestlohn, mindestlohn_tabelle$Arbeitslosenquote)
kovariation <- cov(mindestlohn_tabelle$Mindestlohn, mindestlohn_tabelle$Arbeitslosenquote)
kovariation
b <- (standardabweichungQuote / standardabweichungLohn) * korrelation
b
a <- (-(standardabweichungQuote / standardabweichungLohn) * korrelation * mittelwertLohn + mittelwertQuote)
a
#Regressionsgleichung
erwarteteQuote <- (b * 12.00) + a
erwarteteQuote
# Fit regression line
require(stats)
regression <-lm(mindestlohn_tabelle$Arbeitslosenquote ~ mindestlohn_tabelle$Mindestlohn, data = mindestlohn_tabelle)
# plot
plot(mindestlohn_tabelle, main=eq)
abline(regression, col="blue")
#Die Regressionsgerade zeigt, dass die Arbeitslosenquote mit der Höhe des Mindestlohns abnimmt.
# Da die meisten Datenpunkte jedoch sehr weit entfernt von der Geraden sind, ist eine Vorhersage
# nicht möglich. Die Regressionsgerade ist daher nicht geeignet um die Daten zu interpretieren.
regression #Intercept: 9.07, mindeslohn: -0.39
summary(regression) #erste Werte gleich (Estimate)
# "regression" gibt nur die Regressionskoeffizienten b und a aus, während "summary(regression") genauere
# Daten liefert, wie z.B. die FÜnf-Punkte-Zusammenfassung der Fehler d.h. die Abweichung der Arbeitslosenquote von der Geraden und die Standardabweichung der Fehler.
#
regression <-lm(mindestlohn_tabelle$Arbeitslosenquote ~ mindestlohn_tabelle$Mindestlohn)
regression <-lm(mindestlohn_tabelle$Arbeitslosenquote ~ mindestlohn_tabelle$Mindestlohn)
main
plot(mindestlohn_tabelle$Mindestlohn, mindestlohn_tabelle$Arbeitslosenquote)
#Es gibt keinen linearen Zusammenhang.
mittelwertQuote <- mean(mindestlohn_tabelle$Arbeitslosenquote)
mittelwertLohn <- mean(mindestlohn_tabelle$Mindestlohn)
standardabweichungQuote <- sd(mindestlohn_tabelle$Arbeitslosenquote)
standardabweichungLohn <- sd(mindestlohn_tabelle$Mindestlohn)
korrelation <- cor(mindestlohn_tabelle$Mindestlohn, mindestlohn_tabelle$Arbeitslosenquote)
kovariation <- cov(mindestlohn_tabelle$Mindestlohn, mindestlohn_tabelle$Arbeitslosenquote)
kovariation
b <- (standardabweichungQuote / standardabweichungLohn) * korrelation
b
a <- (-(standardabweichungQuote / standardabweichungLohn) * korrelation * mittelwertLohn + mittelwertQuote)
a
#Regressionsgleichung
erwarteteQuote <- (b * 12.00) + a
erwarteteQuote
# Fit regression line
require(stats)
regression <-lm(mindestlohn_tabelle$Arbeitslosenquote ~ mindestlohn_tabelle$Mindestlohn)
# plot
plot(mindestlohn_tabelle, main=eq)
abline(regression, col="blue")
#Die Regressionsgerade zeigt, dass die Arbeitslosenquote mit der Höhe des Mindestlohns abnimmt.
# Da die meisten Datenpunkte jedoch sehr weit entfernt von der Geraden sind, ist eine Vorhersage
# nicht möglich. Die Regressionsgerade ist daher nicht geeignet um die Daten zu interpretieren.
regression #Intercept: 9.07, mindeslohn: -0.39
summary(regression) #erste Werte gleich (Estimate)
# "regression" gibt nur die Regressionskoeffizienten b und a aus, während "summary(regression") genauere
# Daten liefert, wie z.B. die FÜnf-Punkte-Zusammenfassung der Fehler d.h. die Abweichung der Arbeitslosenquote von der Geraden und die Standardabweichung der Fehler.
#
# plot
plot(mindestlohn_tabelle, main=eq)
regression <-lm(mindestlohn_tabelle$Arbeitslosenquote ~ mindestlohn_tabelle$Mindestlohn)
# plot
plot(mindestlohn_tabelle, main=eq)
abline(regression, col="blue")
plot(mindestlohn_tabelle, main=eq)
abline(regression, col="blue")
x <- runif(100, 0, 100)
e <- runif(100, 0, 50)
y <- x^2 + x * e
data <- data.frame(x, y)
mittelwertX <- mean(x)
mittelwertY <- mean(y)
standardabweichungX <- sd(x)
standardabweichungY <- sd(y)
korrelation <- cor(x, y)
kovariation <- cov(x, y)
kovariation
b <- (standardabweichungY / standardabweichungX) * korrelation
b
a <- (-(standardabweichungY / standardabweichungX) * korrelation * mittelwertX + mittelwertY)
a
c <- ((y/6)-(b*(x/6))-(a*(x*2/6)))
c
#Regressionsgleichung
#linear
linearModel <- (b * x) + a
#quadratisch
quadraticModel <- lm(formula = y ~ poly(x, 2), data = data)
quadraticModel
#Kubisch
#cubicModel <- lm(formula = y ~ a + poly(x, 3) + b + poly(x, 2) + c*x, data=data)
#cubicModel
#Modellzusammenfassung anzeigen
summary(linearModel)
summary(quadraticModel)
summary(cubicModel)
x <- runif(100, 0, 100)
e <- runif(100, 0, 50)
y <- x^2 + x * e
data <- data.frame(x, y)
mittelwertX <- mean(x)
mittelwertY <- mean(y)
standardabweichungX <- sd(x)
standardabweichungY <- sd(y)
korrelation <- cor(x, y)
kovariation <- cov(x, y)
kovariation
b <- (standardabweichungY / standardabweichungX) * korrelation
b
a <- (-(standardabweichungY / standardabweichungX) * korrelation * mittelwertX + mittelwertY)
a
c <- ((y/6)-(b*(x/6))-(a*(x*2/6)))
c
#Regressionsgleichung
#linear
linearModel <- (b * x) + a
#quadratisch
quadraticModel <- lm(formula = y ~ poly(x, 2), data = data)
quadraticModel
#Kubisch
#cubicModel <- lm(formula = y ~ a + poly(x, 3) + b + poly(x, 2) + c*x, data=data)
#cubicModel
#Modellzusammenfassung anzeigen
summary(linearModel)
summary(quadraticModel)
#summary(cubicModel)
#linear Plot
plot(x, y, pch=16)
curve(b*x+a, xlim = c(-2, 2))
#quadratisch Plot
plot(data$x, data$y, type="l", col=2)
points(x2, y)
curve(a*x^2 + b*x)
#kubischer Plot
#curve(a*x^3 + b*x^2 + c*x)
x <- runif(100, 0, 100)
e <- runif(100, 0, 50)
y <- x^2 + x * e
data <- data.frame(x, y)
mittelwertX <- mean(x)
mittelwertY <- mean(y)
standardabweichungX <- sd(x)
standardabweichungY <- sd(y)
korrelation <- cor(x, y)
kovariation <- cov(x, y)
kovariation
b <- (standardabweichungY / standardabweichungX) * korrelation
b
a <- (-(standardabweichungY / standardabweichungX) * korrelation * mittelwertX + mittelwertY)
a
c <- ((y/6)-(b*(x/6))-(a*(x*2/6)))
c
#Regressionsgleichung
#linear
linearModel <- (b * x) + a
#quadratisch
quadraticModel <- lm(formula = y ~ poly(x, 2), data = data)
quadraticModel
#Kubisch
#cubicModel <- lm(formula = y ~ a + poly(x, 3) + b + poly(x, 2) + c*x, data=data)
#cubicModel
#Modellzusammenfassung anzeigen
summary(linearModel)
summary(quadraticModel)
#summary(cubicModel)
#linear Plot
plot(x, y, pch=16)
curve(b*x+a, xlim = c(-2, 2))
#quadratisch Plot
plot(data$x, data$y, type="l", col=2)
points(x, y)
curve(a*x^2 + b*x)
#kubischer Plot
#curve(a*x^3 + b*x^2 + c*x)
mietspiegel <- read.table("miete03.asc", header=TRUE)
#a)
plot(mietspiegel$wfl, mietspiegel$nm)
abline(lm(mietspiegel$wfl~mietspiegel$nm))
#b)
mittelwertNm <- mean(mietspiegel$nm)
mittelwertWfl <- mean(mietspiegel$wfl)
standardabweichungNm <- sd(mietspiegel$nm)
standardabweichungWfl <- sd(mietspiegel$wfl)
korrelation <- cor(mietspiegel$wfl, mietspiegel$nm)
kovariation <- cov(mietspiegel$wfl, mietspiegel$nm)
kovariation
b <- (standardabweichungNm / standardabweichungWfl) * korrelation
b
a <- (-(standardabweichungNm / standardabweichungWfl) * korrelation * mittelwertWfl + mittelwertNm)
a
#Regressionsgleichung
erwarteteNettomiete60 <- (b * 60) + a
erwarteteNettomiete100 <- (b * 100) + a
erwarteteNettomiete150 <- (b * 150) + a
erwarteteNettomiete60
erwarteteNettomiete100
erwarteteNettomiete150
#c)
regression <-lm( mietspiegel$nm ~ mietspiegel$wfl, data = mietspiegel)
summary(regression)
# 89% der Nettomiete wird durch die Wohnfläche erklärt.
#c)
regression <-lm( mietspiegel$nm ~ mietspiegel$wfl, data = mietspiegel)
regression <-lm( mietspiegel$nm ~ mietspiegel$wfl, data = mietspiegel)
summary(regression)
regression$coefficients
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
betriebe_daten <- matrix(c(639,64,41,487,131,41,203,153,33,54,91,17,46,112,18),
nrow=5, ncol=3, byrow=T,
dimnames=list(c("[0,50)", "[50, 180)",
"[180, 500)", "[500, 1000)", ">= 1000"),
c("Vollzeit", "Nebenerwerb", "Pacht")))
kable(betriebe_daten)
library(DescTools)
library(vcd)
#a)
assocstats(betriebe_daten)
#b)
kontingenztabelleZV <- margin.table(betriebe_daten,1)
kontingenztabelleSV <- margin.table(betriebe_daten,2)
n <- sum(betriebe_daten)
betriebe_daten_erwartet <- betriebe_daten
for (i in 1:length(kontingenztabelleZV)){
for (j in 1:length(kontingenztabelleSV)){
betriebe_daten_erwartet[i,j] <- (kontingenztabelleZV[i] * kontingenztabelleSV[j]) / n
}
}
betriebe_daten_erwartet
ExpFreq(betriebe_daten)
#c)
prop.table(betriebe_daten_erwartet)
#d)
mosaicplot(betriebe_daten)
mosaicplot(betriebe_daten_erwartet)
#e)
assocstats(betriebe_daten_erwartet)
daten <- matrix(c(223, 75, 107, 21), nrow=2, byrow=T,
dimnames=list(c("mit Creme","ohne Creme"),
c("besser","schlechter")))
kable(daten)
#a)
bedRelativeHaeufigkeiten <- round(prop.table(daten), digits = 3)
bedRelativeHaeufigkeiten
# Werden nur die beiden bedingten Häufigkeiten betrachtet, wird der Eindruck gewonnen, dass die Anwendung der Salbe sinnvoll ist, da diese bei 52,3% der Anwender wirkt und nur bei 25,1% also der Hälfte weniger, der Ausschlag auch ohne Salbe besser wird. Um signifikante Aussagen treffen zu können, sollten auch die restlichen bedingten Häufigkeiten betrachtet werden.
#b)
ExpFreq(daten)
#c)
assocstats(daten)
# Pearson beträgt 0,04. Es besteht nur eine äußerst leichte Abhängigkeit
# bzw. ein sehr schwacher Zusammenhang zwischen den Daten.
# Chi^2 sagt wenig aus, da dieser Wert nicht standardisiert ist. Die gleichwertigen Koeffizienten
# nach Cramer und der Kontingenzkoeffizient sagen jedoch aus, dass es nur einen schwachen Zusammenhang gibt, d.h. es besteht ein hohes Maß an Unabhängigkeit der
# Daten.
#d)
daten2 <- matrix(c(298, 0, 0, 128), nrow=2, byrow=T,
dimnames=list(c("mit Creme","ohne Creme"),
c("besser","schlechter")))
kable(daten2)
assocstats(daten2)
# Nach Pearson (0) besteht kein Zusammenhang zwischen den Daten.
# Die Koeffizienten besagen jedoch, dass ein sehr starker Zusammenhang zwischen den Daten besteht. Dadurch, dass zwei von vier Werte 0 betragen, kann es sein, dass der
# Pearson Wert verzerrt ist
# Die Koeffizienten zeigen den perfekten/maximalen Zusammenhang auf (mit Creme besser, ohne Creme schlechter).
#e)
assocstats(betriebe_daten_erwartet)
#c)
assocstats(daten)
assocstats(daten2)
shiny::runApp('C:/Users/Swanpride/Downloads')
library(shiny); runApp('C:/Users/Swanpride/AppData/Local/Microsoft/Windows/INetCache/IE/YIOW845H/app[1].r')
library(shiny)
library(shiny)
covidData <- read.csv("./RKI_COVID19_Berlin.csv")
setwd("C:/Users/Swanpride/Projekte/CovidStatistikHausarbeit")
covidData <- read.csv("./RKI_COVID19_Berlin.csv")
bezirkNamen <- unique(covidData$Landkreis)
bezirkNamen
runApp()
BezirkTode <- table(covidData$Landkreis[todesfall])
todesfall <- covidData$AnzahlTodesfall != "0"
BezirkTode <- table(covidData$Landkreis[todesfall])
BezirkTode
runApp()
runApp()
GeschlechtData
library(shiny)
covidData <- read.csv("./RKI_COVID19_Berlin.csv")
geschlechter <- unique(covidData$Geschlecht)
GeschlechtFaelle <- table(covidData$Geschlecht[fall])
GeschlechtTode <- table(covidData$Geschlecht[todesfall])
GeschlechtData <- rbind(GeschlechtFaelle[geschlechter], GeschlechtTode[geschlechter])
fall <- covidData$AnzahlFall != "0"
todesfall <- covidData$AnzahlTodesfall != "0"
geschlechter <- unique(covidData$Geschlecht)
GeschlechtFaelle <- table(covidData$Geschlecht[fall])
GeschlechtTode <- table(covidData$Geschlecht[todesfall])
GeschlechtData <- rbind(GeschlechtFaelle[geschlechter], GeschlechtTode[geschlechter])
GeschlechtData
covidData["Geschlecht"]
covidData$Geschlecht
covidData[, "Geschlecht"]
runApp()
datenfarben <- c(
"AnzahlGenesen" = "green",
"AnzahlFall" = "blue",
"AnzahlTodesfall" = "red"
)
datenfarben[, "AnzahlGenesen"]
datenfarben["AnzahlGenesen"]
runApp()
runApp()
